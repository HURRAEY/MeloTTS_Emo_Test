#!/usr/bin/env python3
import os
import sys
import argparse
import json
import torch
import torch.nn.functional as F
from torch.utils.data import DataLoader
from torch.utils.tensorboard import SummaryWriter

# MeloTTS ê²½ë¡œ ì¶”ê°€
sys.path.append('MeloTTS/melo')

from melo import commons, utils
from melo.data_utils_emotion import TextAudioSpeakerEmotionLoader, TextAudioSpeakerEmotionCollate
from melo.models_emotion import SynthesizerTrnEmotion
from melo.models import MultiPeriodDiscriminator
from melo.mel_processing import mel_spectrogram_torch, spec_to_mel_torch

def main():
    # ì„¤ì • ë¡œë“œ
    with open('MeloTTS/melo/configs/config.json') as f:
        config = json.load(f)
    hps = utils.HParams(**config)
    
    with open('emotion_config.json') as f:
        emotion_config = json.load(f)
    
    # ë””ë ‰í† ë¦¬ ì„¤ì •
    hps.model_dir = "checkpoints/emotion_melotts"
    os.makedirs(hps.model_dir, exist_ok=True)
    
    # CPU ë””ë°”ì´ìŠ¤ ì„¤ì •
    device = torch.device('cpu')
    print(f"Using device: {device}")
    
    # ë°ì´í„° ë¡œë” (ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš©)
    train_files = hps.data.training_files.replace('../', '')
    val_files = hps.data.validation_files.replace('../', '')
    train_dataset = TextAudioSpeakerEmotionLoader(train_files, hps.data)
    val_dataset = TextAudioSpeakerEmotionLoader(val_files, hps.data)
    
    train_loader = DataLoader(
        train_dataset, 
        batch_size=2,  # ì‘ì€ ë°°ì¹˜ ì‚¬ì´ì¦ˆë¡œ ì‹œì‘
        shuffle=True, 
        num_workers=1,  # CPUì—ì„œëŠ” 1ë¡œ ì„¤ì •
        collate_fn=TextAudioSpeakerEmotionCollate(),
        pin_memory=False  # CPUì—ì„œëŠ” False
    )
    
    # ëª¨ë¸ ì´ˆê¸°í™”
    net_g = SynthesizerTrnEmotion(
        len(hps.data.symbols),
        hps.data.filter_length // 2 + 1,
        hps.train.segment_size // hps.data.hop_length,
        n_speakers=hps.data.n_speakers,
        n_emotions=emotion_config['model']['n_emotions'],
        emotion_channels=emotion_config['model']['emotion_channels'],
        **hps.model
    ).to(device)
    
    net_d = MultiPeriodDiscriminator(hps.model.use_spectral_norm).to(device)
    
    # ìµœì í™”ê¸°
    optimizer_g = torch.optim.AdamW(net_g.parameters(), 0.0001)  # ë‚®ì€ í•™ìŠµë¥ 
    optimizer_d = torch.optim.AdamW(net_d.parameters(), 0.0001)
    
    # ë¡œê±°
    logger = utils.get_logger(hps.model_dir)
    writer = SummaryWriter(log_dir=hps.model_dir)
    
    print("ğŸµ ê°ì • ì§€ì› MeloTTS í›ˆë ¨ ì‹œì‘!")
    
    # ê°„ë‹¨í•œ í›ˆë ¨ ë£¨í”„
    net_g.train()
    net_d.train()
    
    for epoch in range(2):  # 2 ì—í¬í¬ë§Œ í…ŒìŠ¤íŠ¸
        for batch_idx, batch in enumerate(train_loader):
            if batch_idx >= 3:  # 3 ë°°ì¹˜ë§Œ í…ŒìŠ¤íŠ¸
                break
                
            x, x_lengths, y, y_lengths, sid, emotion_ids, tone, language, bert, ja_bert = batch
            
            # CPUë¡œ ì´ë™
            x, x_lengths = x.to(device), x_lengths.to(device)
            y, y_lengths = y.to(device), y_lengths.to(device) 
            sid = sid.to(device)
            emotion_ids = emotion_ids.to(device)
            tone = tone.to(device)
            language = language.to(device)
            bert = bert.to(device)
            ja_bert = ja_bert.to(device)
            
            try:
                # Forward pass
                y_hat, l_length, attn, ids_slice, x_mask, z_mask, \
                (z, z_p, m_p, logs_p, m_q, logs_q) = net_g(
                    x, x_lengths, y, y_lengths, sid, emotion_ids, tone, language, bert, ja_bert
                )
                
                # Loss ê³„ì‚° (ê°„ì†Œí™”)
                mel = spec_to_mel_torch(
                    y, hps.data.filter_length, hps.data.n_mel_channels, 
                    hps.data.sampling_rate, hps.data.mel_fmin, hps.data.mel_fmax
                )
                
                y_mel = commons.slice_segments(mel, ids_slice, hps.train.segment_size // hps.data.hop_length)
                y_hat_mel = mel_spectrogram_torch(
                    y_hat.squeeze(1), hps.data.filter_length, hps.data.n_mel_channels,
                    hps.data.sampling_rate, hps.data.hop_length, hps.data.win_length,
                    hps.data.mel_fmin, hps.data.mel_fmax
                )
                
                loss_mel = F.l1_loss(y_mel, y_hat_mel)
                loss_dur = torch.sum(l_length.float())
                loss = loss_mel + loss_dur * 0.1
                
                # Backward
                optimizer_g.zero_grad()
                loss.backward()
                optimizer_g.step()
                
                print(f"Epoch {epoch}, Batch {batch_idx}, Loss: {loss.item():.4f}")
                
            except Exception as e:
                print(f"ë°°ì¹˜ {batch_idx}ì—ì„œ ì˜¤ë¥˜ ë°œìƒ: {e}")
                continue
    
    print("âœ… í…ŒìŠ¤íŠ¸ í›ˆë ¨ ì™„ë£Œ!")
    
    # ì²´í¬í¬ì¸íŠ¸ ì €ì¥
    checkpoint_path = os.path.join(hps.model_dir, "test_model.pth")
    torch.save({
        'model': net_g.state_dict(),
        'epoch': 2
    }, checkpoint_path)
    print(f"ëª¨ë¸ ì €ì¥: {checkpoint_path}")

if __name__ == "__main__":
    main() 